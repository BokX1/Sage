# =============================================================================
# Sage Discord Bot - Environment Configuration
# =============================================================================
# IMPORTANT: Never commit this file with real values!
# Copy to .env and fill in your actual values.
# =============================================================================

# -----------------------------------------------------------------------------
# Core / Discord Configuration (REQUIRED)
# -----------------------------------------------------------------------------
NODE_ENV=production
DISCORD_TOKEN=YOUR_DISCORD_TOKEN_HERE
DISCORD_APP_ID=YOUR_APP_ID_HERE
DATABASE_URL="postgresql://postgres:password@localhost:5432/sage?schema=public"
DEV_GUILD_ID=

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------
LLM_PROVIDER=pollinations
LLM_BASE_URL=https://gen.pollinations.ai/v1
CHAT_MODEL=openai-large
# Note: Sage uses agent-aware model policy (for example, qwen-coder for coding and perplexity-fast for search).
LLM_IMAGE_BASE_URL=https://gen.pollinations.ai
# Optional: set a global key for higher limits or leave blank and use /sage key set per server
# [NOTE] If left blank, servers MUST provide their own key (BYOP) via /sage key set.
# Get a key at https://pollinations.ai/ or their Discord.
LLM_API_KEY=

# Profile Memory LLM Override
PROFILE_PROVIDER=
PROFILE_CHAT_MODEL=deepseek
PROFILE_UPDATE_INTERVAL=5

# Channel Summary Model
SUMMARY_MODEL=openai-large

# Formatter (reliable JSON)
FORMATTER_MODEL=qwen-coder

# Encryption key for at-rest API key encryption (64 hex chars).
# If you use the onboarding wizard, this value is auto-generated.
# Manual setup: openssl rand -hex 32
SECRET_ENCRYPTION_KEY=

# -----------------------------------------------------------------------------
# Message Storage / Ingestion
# -----------------------------------------------------------------------------
INGESTION_ENABLED=true
INGESTION_MODE=all
INGESTION_ALLOWLIST_CHANNEL_IDS_CSV=
INGESTION_BLOCKLIST_CHANNEL_IDS_CSV=
MESSAGE_DB_STORAGE_ENABLED=true
MESSAGE_DB_MAX_MESSAGES_PER_CHANNEL=500
PROACTIVE_POSTING_ENABLED=true
RAW_MESSAGE_TTL_DAYS=3
RING_BUFFER_MAX_MESSAGES_PER_CHANNEL=200
CONTEXT_TRANSCRIPT_MAX_MESSAGES=15
CONTEXT_TRANSCRIPT_MAX_CHARS=24000

# Discord attachment ingestion (non-image files)
# Non-image files are extracted through Apache Tika (with text fallback when needed).
FILE_INGEST_TIKA_BASE_URL=http://127.0.0.1:9998
FILE_INGEST_TIMEOUT_MS=45000
FILE_INGEST_MAX_ATTACHMENTS_PER_MESSAGE=4
FILE_INGEST_MAX_BYTES_PER_FILE=10485760
FILE_INGEST_MAX_TOTAL_BYTES_PER_MESSAGE=20971520
FILE_INGEST_OCR_ENABLED=false

# -----------------------------------------------------------------------------
# Channel Summaries
# -----------------------------------------------------------------------------
SUMMARY_ROLLING_WINDOW_MIN=60
SUMMARY_ROLLING_MIN_MESSAGES=20
SUMMARY_ROLLING_MIN_INTERVAL_SEC=300
SUMMARY_PROFILE_MIN_INTERVAL_SEC=21600
SUMMARY_MAX_CHARS=1800
SUMMARY_SCHED_TICK_SEC=60

# -----------------------------------------------------------------------------
# Bot Behavior
# -----------------------------------------------------------------------------
LOG_LEVEL=info
RATE_LIMIT_MAX=5
RATE_LIMIT_WINDOW_SEC=10
AUTOPILOT_MODE=manual
WAKE_WORDS_CSV=sage
# Optional: prefixes that can precede wake words (e.g., "hey sage")
# Leave empty to only trigger on wake word at start of message
WAKE_WORD_PREFIXES_CSV=
WAKEWORD_COOLDOWN_SEC=10
WAKEWORD_MAX_RESPONSES_PER_MIN_PER_CHANNEL=6

# -----------------------------------------------------------------------------
# Context Budgets
# -----------------------------------------------------------------------------
CONTEXT_MAX_INPUT_TOKENS=120000
CONTEXT_RESERVED_OUTPUT_TOKENS=12000
SYSTEM_PROMPT_MAX_TOKENS=12000
TOKEN_ESTIMATOR=heuristic
TOKEN_HEURISTIC_CHARS_PER_TOKEN=4
CONTEXT_BLOCK_MAX_TOKENS_TRANSCRIPT=20000
CONTEXT_BLOCK_MAX_TOKENS_ROLLING_SUMMARY=12000
CONTEXT_BLOCK_MAX_TOKENS_PROFILE_SUMMARY=12000
CONTEXT_BLOCK_MAX_TOKENS_MEMORY=12000
CONTEXT_BLOCK_MAX_TOKENS_REPLY_CONTEXT=8000
CONTEXT_BLOCK_MAX_TOKENS_PROVIDERS=12000

CONTEXT_USER_MAX_TOKENS=60000
CONTEXT_TRUNCATION_NOTICE=true
CHAT_MAX_OUTPUT_TOKENS=1800
CODING_MAX_OUTPUT_TOKENS=4200
SEARCH_MAX_OUTPUT_TOKENS=2000
CRITIC_MAX_OUTPUT_TOKENS=1800

# -----------------------------------------------------------------------------
# Agentic Runtime / Tracing
# -----------------------------------------------------------------------------
TRACE_ENABLED=true
AGENTIC_GRAPH_PARALLEL_ENABLED=true
AGENTIC_GRAPH_MAX_PARALLEL=2
AGENTIC_TOOL_ALLOW_EXTERNAL_WRITE=false
AGENTIC_TOOL_ALLOW_HIGH_RISK=false
AGENTIC_TOOL_BLOCKLIST_CSV=join_voice_channel,leave_voice_channel
# Optional global policy object merged after legacy flags (and before tenant overrides).
# Example:
# AGENTIC_TOOL_POLICY_JSON={"allowNetworkRead":true,"allowDataExfiltrationRisk":true,"blockedTools":["leave_voice"],"riskOverrides":{"local_llm_infer":"high_risk"}}
AGENTIC_TOOL_POLICY_JSON=
AGENTIC_TOOL_LOOP_ENABLED=true
# Enforce tool-backed evidence on freshness/external-fact turns when tools are available.
AGENTIC_TOOL_HARD_GATE_ENABLED=true
# Minimum successful tool calls required when hard gate triggers.
AGENTIC_TOOL_HARD_GATE_MIN_SUCCESSFUL_CALLS=1
AGENTIC_TOOL_MAX_ROUNDS=2
AGENTIC_TOOL_MAX_CALLS_PER_ROUND=3
AGENTIC_TOOL_TIMEOUT_MS=45000
AGENTIC_TOOL_MAX_OUTPUT_TOKENS=1200
AGENTIC_TOOL_RESULT_MAX_CHARS=4000
AGENTIC_TOOL_PARALLEL_READ_ONLY_ENABLED=true
AGENTIC_TOOL_MAX_PARALLEL_READ_ONLY=3
AGENTIC_CANARY_ENABLED=true
AGENTIC_CANARY_PERCENT=100
AGENTIC_CANARY_ROUTE_ALLOWLIST_CSV=chat,coding,search,creative
AGENTIC_CANARY_MAX_FAILURE_RATE=0.20
AGENTIC_CANARY_MIN_SAMPLES=50
AGENTIC_CANARY_COOLDOWN_SEC=300
AGENTIC_CANARY_WINDOW_SIZE=250
# Persist canary/model-health runtime state in DB (Phase 6). Falls back to in-memory on DB failures.
AGENTIC_PERSIST_STATE_ENABLED=true
# Optional per-tenant agentic overrides.
# Example:
# AGENTIC_TENANT_POLICY_JSON={"default":{"maxParallel":2},"guilds":{"123":{"allowedModels":["openai-fast","deepseek"]}}}
AGENTIC_TENANT_POLICY_JSON={}
AGENTIC_CRITIC_ENABLED=true
# Quality-first default from latest self-judge tuning results.
AGENTIC_CRITIC_MIN_SCORE=0.82
AGENTIC_CRITIC_MAX_LOOPS=2
# Deterministic response validator layer (Phase 3)
AGENTIC_VALIDATORS_ENABLED=true
# Optional per-route override JSON. Example:
# AGENTIC_VALIDATION_POLICY_JSON={"search":{"strictness":"enforce"},"coding":{"strictness":"warn"},"chat":{"strictness":"warn"},"creative":{"strictness":"off"}}
AGENTIC_VALIDATION_POLICY_JSON=
AGENTIC_VALIDATION_AUTO_REPAIR_ENABLED=true
AGENTIC_VALIDATION_AUTO_REPAIR_MAX_ATTEMPTS=1
# Phase 7 manager-worker orchestration (complex coding/search turns).
AGENTIC_MANAGER_WORKER_ENABLED=false
AGENTIC_MANAGER_WORKER_MAX_WORKERS=3
AGENTIC_MANAGER_WORKER_MAX_PLANNER_LOOPS=1
AGENTIC_MANAGER_WORKER_MAX_TOKENS=900
AGENTIC_MANAGER_WORKER_MAX_INPUT_CHARS=32000
AGENTIC_MANAGER_WORKER_TIMEOUT_MS=60000
AGENTIC_MANAGER_WORKER_MIN_COMPLEXITY_SCORE=0.55

# Replay quality gate controls (used by npm run agentic:replay-gate)
REPLAY_GATE_LIMIT=200
REPLAY_GATE_MIN_AVG_SCORE=0.65
REPLAY_GATE_MIN_SUCCESS_RATE=0.75
REPLAY_GATE_MIN_TOOL_EXECUTION_RATE=0.00
REPLAY_GATE_MAX_HARD_GATE_FAILURE_RATE=1.00
REPLAY_GATE_REQUIRE_DATA=1
REPLAY_GATE_MIN_TOTAL=10
REPLAY_GATE_REQUIRED_ROUTES_CSV=chat,coding,search,creative
REPLAY_GATE_MIN_ROUTE_SAMPLES=1
# Optional per-route override JSON. Example:
# REPLAY_GATE_ROUTE_THRESHOLDS_JSON={"search":{"minAvgScore":0.62,"minSuccessRate":0.70,"minToolExecutionRate":0.95,"maxHardGateFailureRate":0.15,"minSamples":20}}
REPLAY_GATE_ROUTE_THRESHOLDS_JSON=
REPLAY_GATE_GUILD_ID=
REPLAY_GATE_CHANNEL_ID=

# Replay seed controls (used by npm run agentic:seed-replay-data)
REPLAY_SEED_PER_ROUTE=3
REPLAY_SEED_GUILD_ID=
REPLAY_SEED_CHANNEL_PREFIX=seed-replay
REPLAY_SEED_USER_ID=seed-user

# Model-judge evaluation run controls (used by npm run eval:run)
EVAL_RUN_LIMIT=40
EVAL_RUN_CONCURRENCY=2
EVAL_RUN_REQUIRE_DATA=1
EVAL_RUN_CLEANUP_EXISTING=1
EVAL_RUN_FAIL_ON_ERROR=1
EVAL_RUN_RUBRIC_VERSION=v1
EVAL_RUN_TIMEOUT_MS=120000
EVAL_RUN_MAX_TOKENS=1200
EVAL_RUN_GUILD_ID=
EVAL_RUN_CHANNEL_ID=
EVAL_RUN_ROUTES_CSV=
EVAL_RUN_OUTPUT_JSON=
EVAL_RUN_API_KEY=
EVAL_RUN_PRIMARY_MODEL=
EVAL_RUN_SECONDARY_MODEL=
EVAL_RUN_ADJUDICATOR_MODEL=

# Model-judge evaluation gate controls (used by npm run eval:gate)
EVAL_GATE_LIMIT=60
EVAL_GATE_REQUIRE_DATA=1
EVAL_GATE_MIN_TOTAL=1
EVAL_GATE_RUBRIC_VERSION=v1
EVAL_GATE_MIN_AVG_SCORE=0.75
EVAL_GATE_MIN_PASS_RATE=0.70
EVAL_GATE_MAX_DISAGREEMENT_RATE=0.40
EVAL_GATE_MIN_CONFIDENCE=0.50
EVAL_GATE_GUILD_ID=
EVAL_GATE_CHANNEL_ID=
EVAL_GATE_ROUTE_KIND=
EVAL_GATE_LATEST_PER_TRACE=1
EVAL_GATE_REQUIRED_ROUTES_CSV=
EVAL_GATE_MIN_ROUTE_SAMPLES=1
# Optional per-route override JSON. Example:
# EVAL_GATE_ROUTE_THRESHOLDS_JSON={"search":{"minAvgScore":0.78,"minPassRate":0.72,"maxDisagreementRate":0.35,"minConfidence":0.55,"minSamples":20}}
EVAL_GATE_ROUTE_THRESHOLDS_JSON=

# Agentic simulation + tuning self-judge controls
# SIM_JUDGE_ENABLED=1
# SIM_JUDGE_WEIGHT=0.55
# SIM_REQUIRE_JUDGE_RESULTS=1
# SIM_MIN_JUDGE_AVG_SCORE=0.68
# SIM_MAX_JUDGE_REVISE_RATE=0.45
# TUNE_JUDGE_ENABLED=1
# TUNE_JUDGE_WEIGHT=0.55



# -----------------------------------------------------------------------------
# Admin Access Control
# -----------------------------------------------------------------------------
ADMIN_ROLE_IDS_CSV=
ADMIN_USER_IDS_CSV=

# -----------------------------------------------------------------------------
# Timeouts (ms)
# -----------------------------------------------------------------------------
TIMEOUT_CHAT_MS=180000
TIMEOUT_SEARCH_MS=90000
TIMEOUT_SEARCH_SCRAPER_MS=150000
TIMEOUT_MEMORY_MS=300000
SEARCH_MAX_ATTEMPTS_SIMPLE=2
SEARCH_MAX_ATTEMPTS_COMPLEX=4
TOOL_WEB_SEARCH_PROVIDER_ORDER=tavily,exa,searxng,pollinations
TOOL_WEB_SEARCH_TIMEOUT_MS=45000
TOOL_WEB_SEARCH_MAX_RESULTS=6
TOOL_WEB_SCRAPE_PROVIDER_ORDER=firecrawl,crawl4ai,jina,raw_fetch
TOOL_WEB_SCRAPE_TIMEOUT_MS=45000
TOOL_WEB_SCRAPE_MAX_CHARS=12000
# Self-host-first profile (if local stack is running):
# TOOL_WEB_SEARCH_PROVIDER_ORDER=searxng,tavily,exa,pollinations
# TOOL_WEB_SCRAPE_PROVIDER_ORDER=crawl4ai,firecrawl,jina,raw_fetch
TAVILY_API_KEY=
EXA_API_KEY=
SEARXNG_BASE_URL=
SEARXNG_SEARCH_PATH=/search
SEARXNG_CATEGORIES=general
SEARXNG_LANGUAGE=en-US
FIRECRAWL_API_KEY=
FIRECRAWL_BASE_URL=https://api.firecrawl.dev/v1
CRAWL4AI_BASE_URL=
CRAWL4AI_BEARER_TOKEN=
JINA_READER_BASE_URL=https://r.jina.ai/http://
GITHUB_TOKEN=
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.1:8b

# -----------------------------------------------------------------------------
# Context Budgeting Advanced
# -----------------------------------------------------------------------------
LLM_MODEL_LIMITS_JSON=""

# -----------------------------------------------------------------------------
# Doctor Utility
# -----------------------------------------------------------------------------
# Set to 1 to enable LLM ping in npm run doctor
LLM_DOCTOR_PING=0
